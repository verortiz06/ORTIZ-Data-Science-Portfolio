{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lKusDZoYu3Zd"
   },
   "source": [
    "## Logistic Regression\n",
    "\n",
    "In this notebook, we'll walk step-by-step through performing logistic regression using the Titanic dataset. We'll cover each of the following steps clearly and thoroughly:\n",
    "\n",
    "1. Loading and inspecting the dataset.\n",
    "2. Preprocessing: Handling missing values and encoding categorical data.\n",
    "3. Splitting the data into training and testing sets.\n",
    "4. Training a logistic regression model.\n",
    "5. Evaluating the model's performance.\n",
    "6. Checking assumptions for logistic regression.\n",
    "7. Interpreting the model's results clearly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MijBWi3T6Hf0"
   },
   "source": [
    "### **Step 1: Load and Inspect the Data**\n",
    "We'll use the Titanic dataset, a popular dataset for predicting passenger survival based on various features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_dBYPNotuwfd"
   },
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "# Load Titanic dataset in seaborn\n",
    "df = sns.load_dataset('titanic')\n",
    "\n",
    "# Inspect the dataset\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aSakmgEGvE78"
   },
   "source": [
    "## **Step 2: Preprocess the Data**\n",
    "Before training our model, we must prepare the dataset. This step involves two key processes:\n",
    "\n",
    "*2.1 Handle Missing Values*\n",
    "Logistic regression requires datasets without missing values, so we remove rows with missing data in important columns (age, embarked).\n",
    "\n",
    "*2.2 Encode Categorical Variables*\n",
    "Machine learning algorithms require numerical inputs. Therefore, categorical variables (sex, embarked) must be converted into numeric form using one-hot encoding.\n",
    "\n",
    "- Why encoding?\n",
    "    - Converts categorical labels into numeric values that the model can interpret.\n",
    "    - Avoids misinterpretation of categorical variables as numeric variables (e.g., treating \"male\" as numerically greater or less than \"female\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xtx_7MlTvIcD"
   },
   "outputs": [],
   "source": [
    "# Handling missing values\n",
    "\n",
    "# Encoding categorical variables\n",
    "# Use drop_first = True to avoid \"dummy trap\"\n",
    "\n",
    "# Define features and target\n",
    "\n",
    "\n",
    "# Preview the cleaned dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hpc_vEn37QSS"
   },
   "source": [
    "## **Step 3: Split the Data**\n",
    "We divide our dataset into two subsets:\n",
    "- *Training Set*: To build our logistic regression model.\n",
    "- *Testing Set*: To evaluate the performance of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yblwppiF7ya3"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Split dataset into training and testing subsets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YKlqE7L676_S"
   },
   "source": [
    "## **Step 4: Train the Logistic Regression Model**\n",
    "We'll now build and train our logistic regression model using the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n1MnU_HRu2iL"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Initialize and train logistic regression model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vQWLzTL58K2r"
   },
   "source": [
    "## **Step 5: Evaluate the Model**\n",
    "To understand how well our model predicts survival, we use the following evaluation metrics:\n",
    "- *Accuracy*: Proportion of correct predictions.\n",
    "- *Confusion Matrix*: Breakdown of predictions (True positives, True negatives, False positives, False negatives).\n",
    "- *Classification Report*: Precision, recall, and F1-score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lPJLnzvu8DkM"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Predict on test data\n",
    "\n",
    "# Calculate accuracy\n",
    "\n",
    "\n",
    "# Generate confusion matrix\n",
    "\n",
    "# Display classification report\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bsGKbVbU9X6u"
   },
   "source": [
    "## **Step 6: Examining and Interpreting the Model**\n",
    "After training our logistic regression model, let's examine the coefficients to understand their meaning in more detail.\n",
    "- Coefficients in logistic regression represent the effect of each feature on the log-odds of the target (survival in this case).\n",
    "- Positive coefficients increase the odds of the outcome (survival).\n",
    "- Negative coefficients decrease the odds of the outcome (survival).\n",
    "- The magnitude of coefficients shows the strength of each feature's influence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JeALrss89wCO"
   },
   "source": [
    "### 6.1 Interpreting Coefficients\n",
    "After training our logistic regression model, let's examine the coefficients to understand their meaning in more detail.\n",
    "- Coefficients in logistic regression represent the effect of each feature on the log-odds of the target (survival in this case).\n",
    "- Positive coefficients increase the odds of the outcome (survival).\n",
    "- Negative coefficients decrease the odds of the outcome (survival).\n",
    "- The magnitude of coefficients shows the strength of each feature's influence.\n",
    "\n",
    "Output:\n",
    "- Coefficient Interpretation:\n",
    "    - Positive coefficients: Increase the log-odds (and thus probability) of survival.\n",
    "    - Negative coefficients: Decrease the log-odds (and thus probability) of survival.\n",
    "\n",
    "\n",
    "\n",
    "| Feature      | Coefficient | Impact on Survival Probability                      | Explanation                                                    |\n",
    "|--------------|-------------|-----------------------------------------------------|----------------------------------------------------------------|\n",
    "| `pclass`     | -1.21       | Decreases                                           | Lower passenger classes (higher numeric values) decrease survival odds.            |\n",
    "| `age`        | -0.04       | Slight negative impact                              | Older passengers have slightly lower odds of survival.         |\n",
    "| `sibsp`      | -0.35       | Negative impact                                     | Having more siblings/spouses aboard decreases survival odds.   |\n",
    "| `parch`      | -0.05       | Slight negative impact                              | Having more parents/children aboard slightly reduces odds.     |\n",
    "| `fare`       | 0.002      | Very slight positive impact                         | Paying higher fares slightly increases survival odds.          |\n",
    "| `sex_male`   | -2.61       | Strong negative impact                              | Being male greatly decreases the probability of survival.      |\n",
    "| **Intercept**| 5.47        | Baseline log-odds                                   | Baseline survival odds for females with lowest-class, fare, age, ect. |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nXXsbI-39i_X"
   },
   "outputs": [],
   "source": [
    "# Extract coefficients and intercept\n",
    "\n",
    "\n",
    "# Display coefficients\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EZEykx279225"
   },
   "source": [
    "### 6.2 Understanding the `predict_proba` Function\n",
    "Logistic regression outputs probabilities between 0 and 1, indicating the likelihood of belonging to a specific class.\n",
    "- The function predict_proba() returns two columns:\n",
    "    - Probability of class 0 (not survived).\n",
    "    - Probability of class 1 (survived).\n",
    "- Output:\n",
    "    - Each row gives the probability of not surviving (first column) and surviving (second column).\n",
    "    - Useful for making informed decisions based on probabilities rather than just binary predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s6OQE2-T9_Rf"
   },
   "outputs": [],
   "source": [
    "# Get predicted probabilities for the test set\n",
    "\n",
    "\n",
    "# Display probabilities for first 5 test observations\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
